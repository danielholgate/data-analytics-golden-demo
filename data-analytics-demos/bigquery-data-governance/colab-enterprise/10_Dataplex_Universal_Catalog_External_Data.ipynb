{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Wx2xZrPfN2"
      },
      "source": [
        "### <font color='#4285f4'>Overview</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-6J2atTPfN2"
      },
      "source": [
        "Overview: This notebook import metadata from a database (Oracle) running outside of Google Cloud into Dataplex Universal Catalog. It provides an example of how data from external systems can be integrated into the catalog and made available for search.\n",
        "\n",
        "Approach:\n",
        "1. The Aspect Types, Entry Types, and Entry Group found in the metadata import file are first generated in the project via python APIs.\n",
        "2. A json import request file is downloaded from Cloud Storage to the notebook instance.\n",
        "3. The metadata import API is invoked via curl, passing in the import request file. The import process loads the metadata import file for the Oracle database from Cloud Storage into Dataplex Universal Catalog. Note that the import process is async and takes approximately 8 minutes to run.\n",
        "\n",
        "Author:\n",
        "* Daniel Holgate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN2wUQ1tPfN2"
      },
      "outputs": [],
      "source": [
        "# Architecture Diagram\n",
        "from IPython.display import Image\n",
        "Image(url='https://storage.googleapis.com/data-analytics-golden-demo/colab-diagrams/BigQuery-Data-Governance-Automated-Data-Governance.png', width=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-D4JI3QPfN3"
      },
      "source": [
        "### <font color='#4285f4'>Video Walkthrough</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twos9IjzPfN3"
      },
      "source": [
        "TBD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### <font color='#4285f4'>License</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### <font color='#4285f4'>Pip installs</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# PIP Installs (if necessary)\n",
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install google-cloud-dataplex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyL-Rg4Dr_f"
      },
      "source": [
        "### <font color='#4285f4'>Initialize</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYsEVSXp6IP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "import IPython.display\n",
        "import google.auth\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import base64\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import base64\n",
        "import random\n",
        "\n",
        "import re\n",
        "import argparse\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "from google.cloud import dataplex_v1\n",
        "import time\n",
        "\n",
        "import logging\n",
        "from tenacity import retry, wait_exponential, stop_after_attempt, before_sleep_log, retry_if_exception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlHl3bnkFPZ"
      },
      "outputs": [],
      "source": [
        "# Set these (run this cell to verify the output)\n",
        "dataplex_location = \"${dataplex_location}\"\n",
        "governed_data_code_bucket = \"${governed_data_code_bucket}\"\n",
        "\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "# Format the date and time as desired\n",
        "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "# Get some values using gcloud\n",
        "project_id = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
        "\n",
        "if len(user) != 1:\n",
        "  raise RuntimeError(f\"user is not set: {user}\")\n",
        "user = user[0]\n",
        "\n",
        "print(f\"project_id = {project_id}\")\n",
        "print(f\"user = {user}\")\n",
        "print(f\"dataplex_location = {dataplex_location}\")\n",
        "print(f\"governed_data_code_bucket = {governed_data_code_bucket}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### <font color='#4285f4'>Helper Methods</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import google.auth.transport.requests\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51M89g0Ejmz"
      },
      "source": [
        "### <font color='#4285f4'>Create Dataplex Universal Catalog metadata hierarchy</font>\n",
        "\n",
        "Create the appropriate Dataplex metadata hierarchy (entry types, aspect types, entry group) before loading the metadata import file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_entry_group(\n",
        "    project_id: str, location: str, entry_group_id: str\n",
        ") -> dataplex_v1.EntryGroup:\n",
        "    \"\"\"Create Entry Group identified by entry_group_id, located in project_id, location \"\"\"\n",
        "\n",
        "    with dataplex_v1.CatalogServiceClient() as client:\n",
        "        # The resource name of the Entry Group location\n",
        "        parent = f\"projects/{project_id}/locations/{location}\"\n",
        "        entry_group = dataplex_v1.EntryGroup(\n",
        "            description=f\"Entry group {entry_group_id} description\"\n",
        "        )\n",
        "        create_operation = client.create_entry_group(\n",
        "            parent=parent, entry_group=entry_group, entry_group_id=entry_group_id\n",
        "        )\n",
        "        print(f\"Created Entry Group: projects/{project_id}/locations/{location}/entryGroups/{entry_group_id}\")\n",
        "        return create_operation.result(60)"
      ],
      "metadata": {
        "id": "fTL24X3vn4vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_entry_type(\n",
        "    project_id: str, location: str, entry_type_id: str\n",
        ") -> dataplex_v1.EntryType:\n",
        "    \"\"\"Create Entry Type identified by entry_type_id, located in project_id, location \"\"\"\n",
        "\n",
        "    print(f\"Creating Entry Type {entry_type_id}\")\n",
        "\n",
        "    typeAliases = []\n",
        "\n",
        "    # To improve search and discoverability, create some common aliases for the oracle records\n",
        "    if \"-table\" in entry_type_id:\n",
        "        typeAliases.append(\"TABLE\")\n",
        "\n",
        "    if \"-view\" in entry_type_id:\n",
        "        typeAliases.append(\"VIEW\")\n",
        "\n",
        "    if \"-database\" in entry_type_id:\n",
        "        typeAliases.append(\"DATABASE\")\n",
        "\n",
        "    with dataplex_v1.CatalogServiceClient() as client:\n",
        "        parent = f\"projects/{project_id}/locations/{location}\"\n",
        "        entry_type = dataplex_v1.EntryType(\n",
        "            description=\"description of the entry type\",\n",
        "            type_aliases=typeAliases,\n",
        "            required_aspects=[],\n",
        "        )\n",
        "        create_operation = client.create_entry_type(\n",
        "            parent=parent, entry_type=entry_type, entry_type_id=entry_type_id\n",
        "        )\n",
        "        return create_operation.result(60)"
      ],
      "metadata": {
        "id": "Sfu16BYrsDBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates Dataplex Aspect Types\n",
        "\n",
        "def create_aspect_type(\n",
        "    project_id: str, location: str, aspect_type_id: str,\n",
        ") -> dataplex_v1.AspectType:\n",
        "    \"\"\"Create Aspect Type identified by aspect_type_id, located in project_id, location \"\"\"\n",
        "\n",
        "    aspect_fields = List[dataplex_v1.AspectType.MetadataTemplate]\n",
        "\n",
        "    with dataplex_v1.CatalogServiceClient() as client:\n",
        "        # The resource name of the Aspect Type location\n",
        "        parent = f\"projects/{project_id}/locations/{location}\"\n",
        "\n",
        "        # Define the Aspect Type resource.\n",
        "        # It requires a metadata_template (a JSON schema) to define the\n",
        "        # properties of the Aspect.\n",
        "\n",
        "        aspect_field = dataplex_v1.AspectType.MetadataTemplate(\n",
        "        name=\"name_of_the_field\",\n",
        "        # Metadata Template is recursive structure,\n",
        "        # primitive types such as \"string\" or \"integer\" indicate leaf node,\n",
        "        # complex types such as \"record\" or \"array\" would require nested Metadata Template\n",
        "        type=\"string\",\n",
        "        index=1,\n",
        "        annotations=dataplex_v1.AspectType.MetadataTemplate.Annotations(\n",
        "            description=\"description of the field\"\n",
        "        ),\n",
        "        constraints=dataplex_v1.AspectType.MetadataTemplate.Constraints(\n",
        "            # Specifies if field will be required in Aspect Type.\n",
        "            required=False\n",
        "        ),\n",
        "        )\n",
        "\n",
        "        aspect_fields = [aspect_field]\n",
        "\n",
        "        aspect_type = dataplex_v1.AspectType(\n",
        "            description=f\"description of aspect type {aspect_type_id}\",\n",
        "            metadata_template=dataplex_v1.AspectType.MetadataTemplate(\n",
        "                name=\"name_of_the_template\",\n",
        "                type=\"record\",\n",
        "                # Aspect Type fields, that themselves are Metadata Templates.\n",
        "                record_fields=aspect_fields,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        create_operation = client.create_aspect_type(\n",
        "            parent=parent,\n",
        "            aspect_type=aspect_type,\n",
        "            aspect_type_id=aspect_type_id\n",
        "        )\n",
        "\n",
        "        # Dataplex operations are long-running, so we wait for the result.\n",
        "        # The timeout is set to 120 seconds (2 minutes).\n",
        "        print(\"Waiting for creation operation to complete...\")\n",
        "        try:\n",
        "            response = create_operation.result(timeout=30)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during Aspect Type creation: {e}\")\n",
        "            raise\n",
        "\n",
        "        print(\n",
        "            f\"Successfully created Aspect Type: projects/{project_id}/locations/{location}/aspectTypes/{aspect_type_id}\"\n",
        "        )\n",
        "        return response"
      ],
      "metadata": {
        "id": "D4gMNgxgsJTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create required entry types, aspect types, and entry group for the metadata import file\n",
        "\n",
        "# Oracle dataplex metadata types found in the file\n",
        "entry_types = ['oracle-instace','oracle-database','oracle-schema','oracle-table','oracle-view']\n",
        "aspect_types = ['oracle-instance','oracle-database','oracle-schema','oracle-table','oracle-view']\n",
        "entry_group_id = \"oracle\"\n",
        "\n",
        "successCount = 0\n",
        "\n",
        "# create the entry group\n",
        "try:\n",
        "  create_entry_group(project_id, dataplex_location, entry_group_id)\n",
        "  successCount += 1\n",
        "except Exception as e:\n",
        "  print(f\"Exception creating entry group {entry_group_id}: {e}\")\n",
        "\n",
        "# Create entry types\n",
        "for et in entry_types:\n",
        "  try:\n",
        "    create_entry_type(project_id, dataplex_location,et)\n",
        "    successCount += 1\n",
        "  except Exception as e:\n",
        "    print(f\"Exception creating entry type {et}: {e}\")\n",
        "\n",
        "# Create aspect types\n",
        "for at in aspect_types:\n",
        "  try:\n",
        "    create_aspect_type(project_id, \"global\",at)\n",
        "    successCount += 1\n",
        "  except Exception as e:\n",
        "    print(f\"Exception creating aspect type {at}: {e}\")\n",
        "\n",
        "if successCount == len(entry_types) + len(aspect_types) + 1:\n",
        "  print(\"All dataplex metadata hierarchy types created successfully\")"
      ],
      "metadata": {
        "id": "6o8i9kAWsSsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH10X1BPNhb2"
      },
      "source": [
        "### <font color='#4285f4'>Import the metadata Import file into Dataplex Universal Catalog</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5mcBIKjNhb3"
      },
      "source": [
        "https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.metadataJobs/create\n",
        "\n",
        "Replace the following\n",
        "- project_id         \"your GCP project id\"\n",
        "- dataplex_location   \"target location for the metadata in the dataplex catalog\"\n",
        "\n",
        "```\n",
        "curl -X POST -H 'Content-Type: application/json; charset=utf-8' -H \"Authorization: Bearer $(gcloud -q auth print-access-token)\" \\\n",
        "-d @metadata_import_request.json \\\n",
        "https://dataplex.googleapis.com/v1/projects/${project_id}/locations/${dataplex_location}/metadataJobs?metadataJobId=a001\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_request_file_url = f\"{governed_data_code_bucket}/oracle_exports/metadata_import_request.json\"\n",
        "print(f\"Downloading the import request file from {json_request_file_url}\")\n",
        "\n",
        "!gsutil cp \"$json_request_file_url\" ."
      ],
      "metadata": {
        "id": "VSPpKsJt0NhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "BATCH_ID=$( date '+%d%H%M%S' )\n",
        "echo $BATCH_ID\n",
        "curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "-d @./metadata_import_request.json \\\n",
        "\"https://dataplex.googleapis.com/v1/projects/${project_id}/locations/global/metadataJobs?metadataJobId=a${BATCH_ID}\""
      ],
      "metadata": {
        "id": "bHZmL_PWu9rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nk7Vjx4v0Btr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IxhtRRrvR-"
      },
      "source": [
        "### <font color='#4285f4'>Clean Up</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lF2Z7skFbvf"
      },
      "outputs": [],
      "source": [
        "# Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQ2BPisXDA0"
      },
      "source": [
        "### <font color='#4285f4'>Reference Links</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTY6xJdZ3ul8"
      },
      "source": [
        "- [REPLACE-ME](https://REPLACE-ME)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "U7Wx2xZrPfN2",
        "i-D4JI3QPfN3",
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "sZ6m_wGrK0YG"
      ],
      "name": "10-Dataplex-Universal-Catalog-External-Data.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}